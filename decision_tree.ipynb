{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree for N-dimensional data and labels\n",
    "The code below implements a decision tree calculated on all the data, for one label depending on several independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "First, some libraries are loaded and global figure settings are made for exporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import log, e\n",
    "import pylab\n",
    "\n",
    "# Figure settings\n",
    "F = pylab.gcf()\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTwoClusters(mean1, mean2, cov1, cov2, npoints):\n",
    "    \"\"\"\n",
    "    Generate `npoints` random points within two clusters characteristed by their `mean` and `diagonal covariance`\n",
    "    \"\"\"\n",
    "    x1, y1 = np.random.multivariate_normal(mean1, cov1, npoints).T\n",
    "    x2, y2 = np.random.multivariate_normal(mean2, cov2, npoints).T\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "\n",
    "def plotData(cluster1,cluster2):\n",
    "    \"\"\"\n",
    "    Plot the clustered data\n",
    "    \"\"\"\n",
    "    plt.plot(cluster1[:,0], cluster1[:,1], 'x')\n",
    "    plt.plot(cluster2[:,0], cluster2[:,1], 'o')\n",
    "    plt.axis('equal')\n",
    "    plt.grid()\n",
    "    plt.savefig('/Users/cyrilwendl/Documents/EPFL/Projet SIE/SIE-Project/random_data.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def entropy(labels, base=None):  # [1]\n",
    "    \"\"\"\n",
    "    Calculate the entropy for a set of labels\n",
    "    \"\"\"\n",
    "    value, counts = np.unique(labels, return_counts=True)\n",
    "    norm_counts = counts / counts.sum()\n",
    "    base = e if base is None else base\n",
    "    return np.abs(-(norm_counts * np.log(norm_counts) / np.log(base)).sum())\n",
    "\n",
    "def differentialEntropy():\n",
    "    \"\"\"\n",
    "    # TODO implement: Gaussian entropy for continuous variables\n",
    "    \"\"\"\n",
    "    pass\n",
    "    \n",
    "\n",
    "def split(index, value, dataset):  # [2]\n",
    "    \"\"\"\n",
    "    split a dataset (columns: variables, rows: data) in two according to some column (index) value \n",
    "    \"\"\"\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "def entropy_discrete(dataset, col_index):\n",
    "    \"\"\"\n",
    "    calculate the entropy values for all cuts on one attribute (left<cut, right>=cut).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset :\n",
    "        Input array with data and label in rows. The last column contains the labels.\n",
    "    col_index :\n",
    "        The index of the column for which the entropy should be computed.\n",
    "    \"\"\"\n",
    "    x_vals, entropy_vals = list(), list()\n",
    "    uniquevals=(np.unique(dataset[:,col_index]))\n",
    "    for split_x in uniquevals[1:]:\n",
    "        x_vals.append(split_x)\n",
    "\n",
    "        # split\n",
    "        left, right = split(col_index, split_x, dataset)\n",
    "        left = np.asarray(left)\n",
    "        right = np.asarray(right)\n",
    "\n",
    "        # labels\n",
    "        left_labels = left[:, -1]  # last column = labels\n",
    "        right_labels = right[:, -1]\n",
    "\n",
    "        # entropy\n",
    "        left_entropy = entropy(left_labels, base=2)\n",
    "        right_entropy = entropy(right_labels, base=2)\n",
    "\n",
    "        # total entropy for attribute\n",
    "        entropy_attr_split = left_entropy * len(left) / len(dataset) + right_entropy * len(right) / len(dataset)\n",
    "        entropy_vals.append(entropy_attr_split)\n",
    "\n",
    "    return entropy_vals, x_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "Next, some data is generated to test the functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD7CAYAAACPDORaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkAeAhBHyAJCw/wf1eAk/V7HylwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115e27630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cluster parameters\n",
    "mean1 = [18, 30]\n",
    "cov1 = [[1, 0], [0, 1]]  # diagonal covariance\n",
    "mean2 = [15, 40]\n",
    "cov2 = [[2, 0], [0, 2]]  # diagonal covariance\n",
    "npoints=50\n",
    "\n",
    "x1,y1,x2,y2=createTwoClusters(mean1,mean2,cov1,cov2,npoints)\n",
    "\n",
    "# zip for having tuples (x,y), round and unique for having discrete coordinates (eliminating duplicate points)\n",
    "cluster1=np.unique(np.round(list(zip(x1,y1,np.ones(len(x1))))),axis=0) # np.ones: label 1 for first cluster\n",
    "cluster2=np.unique(np.round(list(zip(x2,y2,np.ones(len(x2))*2))),axis=0) # np.ones*2: label 2 for second cluster\n",
    "\n",
    "# connect unique points of cluster 1 and cluster 2\n",
    "ataset=np.asarray(np.concatenate((cluster2,cluster1),axis=0))\n",
    "plotData(cluster1,cluster2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>cut value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969062</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.874532</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.681936</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.474953</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.254446</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.152634</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.148736</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.326977</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.609284</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.800414</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.973171</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     entropy  cut value\n",
       "0   0.969062       29.0\n",
       "1   0.874532       30.0\n",
       "2   0.681936       31.0\n",
       "3   0.474953       32.0\n",
       "4   0.254446       33.0\n",
       "5   0.152634       34.0\n",
       "6   0.000000       37.0\n",
       "7   0.148736       38.0\n",
       "8   0.326977       39.0\n",
       "9   0.609284       40.0\n",
       "10  0.800414       41.0\n",
       "11  0.973171       42.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs=[]#pd.DataFrame(columns=([\"x\",\"y\"])\n",
    "entropy_attr=[]\n",
    "x_attr=[]\n",
    "attributes=[\"x\",\"y\"]\n",
    "\n",
    "for attribute_ind in range(np.shape(dataset,)[1]-1):\n",
    "    entropy_vals_attr, xs_vals_attr = entropy_discrete(col_index=attribute_ind, dataset=dataset)\n",
    "    x_attr.append(xs_vals_attr)\n",
    "    entropy_attr.append(np.asarray(entropy_vals_attr))\n",
    "    \n",
    "    df=pd.DataFrame(x_attr[attribute_ind], entropy_attr[attribute_ind])\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns=([\"entropy\",\"cut value\"])\n",
    "    dfs.append(df)\n",
    "\n",
    "dfs[1] # y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to get the variable for which the minimum entropy is lowest and make a cut there. Then continue on recursively until all labels are in the same split subarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>lowest entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.0</th>\n",
       "      <td>cut value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>variable number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            indicator\n",
       "0.0    lowest entropy\n",
       "37.0        cut value\n",
       "1.0   variable number"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].entropy.min()\n",
    "min_val=2 # over value range [0,1], min < min_vals will be necessarily true during first evaluation\n",
    "min_val_cut=np.nan\n",
    "min_var=np.nan\n",
    "for i in range(len(dfs)):\n",
    "    df=dfs[i]\n",
    "    min_df=df.loc[df['entropy'].argmin()]\n",
    "    if min_df[\"entropy\"] < min_val:\n",
    "        min_val = min_df[\"entropy\"] \n",
    "        min_val_cut = min_df[\"cut value\"] \n",
    "        min_var=i\n",
    "        \n",
    "df=pd.DataFrame([\"lowest entropy\",\"cut value\",\"variable number\"],[min_val,min_val_cut,min_var])\n",
    "df.columns=[\"indicator\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate the same procedure over the both splitted sides until there is no split left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get left (l) and right (r) based on split\n",
    "# check if labels unique \n",
    "# get entropies for all split values in ll rr\n",
    "# recurse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO add code for continous entropy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
